#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
High Probability Live Trading Signal Generator (Refined for Swing Trading)

This script:
1. Loads long-term historical symbol performance data.
2. Scans specified stock lists (European, S&P 500, S&P 400) for
   high probability setups using yfinance for the current day.
3. Applies a strict win_rate_threshold (e.g., 0.9).
4. Selects a maximum of ONE trade candidate per day, using historical
   performance as a tie-breaker if multiple setups have the same high score.
5. Outputs the details of the selected trade for potential notification.

User manages weekly trade limits (e.g., max 3 per week) manually.
"""

import os
import logging
import warnings
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import yfinance as yf
from tqdm import tqdm
from collections import OrderedDict 
from typing import Any # Add this import
from pathlib import Path

# Suppress warnings
warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- Path Constants ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_BASE_DIR = os.path.dirname(SCRIPT_DIR) 
DATA_DIR = os.path.join(PROJECT_BASE_DIR, 'data') 

# --- Path to historical performance file (generated by create_historical_performance.py) ---
LONG_TERM_PERF_RESULTS_DIR = os.path.join(PROJECT_BASE_DIR, 'results', 'long_term_historical_perf')
HISTORICAL_STATS_FOR_RANKING_FILE = os.path.join(LONG_TERM_PERF_RESULTS_DIR, 'historical_symbol_performance_long_term.csv')

TICKER_FILES = {
    'euro': os.path.join(DATA_DIR, 'euro_tickers.csv'),
    'sp500': os.path.join(DATA_DIR, 'sp500_tickers.csv'),
    'sp400': os.path.join(DATA_DIR, 'sp400_tickers.csv'),
}

DEFAULT_SYMBOLS = { # Shortened for brevity
    'euro': ['ASML.AS', 'SAP.DE'], 'sp500': ['AAPL', 'MSFT'], 'sp400': ['XPO', 'HUBB']
} 

# --- MODIFIED: Strategy parameters for live scanning ---
STRATEGY_PARAMS = {
    'win_rate_threshold': 0.9, # Set to 0.9 as per backtest insights
    'risk_reward_ratio_threshold': 1.5, # Should match backtester
    'atr_multiplier': 1.5,
    'target_multiplier': 2.0,
    'volume_spike_threshold': 2.0,
    'prioritize_volume_spike': True, 
    'prioritize_low_tier': True,    
    'min_data_days': 250 
}

DATA_FETCH_PERIOD = "2y" # How much historical data to fetch for indicator calculation

# Define SCORE_BINS for trade distribution summary
SCORE_BINS = [
    (0.0, 0.7), 
    (0.7, 0.8), 
    (0.8, 0.9), 
    (0.9, 0.95), 
    (0.95, 1.01) # Upper bound is exclusive, so 1.01 to include 1.0
]

# Global DataFrame for historical performance
long_term_historical_perf_df = None


def load_long_term_historical_stats():
    """Loads the long-term historical symbol performance data."""
    global long_term_historical_perf_df
    if os.path.exists(HISTORICAL_STATS_FOR_RANKING_FILE):
        try:
            long_term_historical_perf_df = pd.read_csv(HISTORICAL_STATS_FOR_RANKING_FILE)
            logger.info(f"Successfully loaded long-term historical symbol stats from {HISTORICAL_STATS_FOR_RANKING_FILE}")
            if not all(col in long_term_historical_perf_df.columns for col in ['symbol', 'hist_strength_score', 'hist_win_rate', 'hist_total_trades']):
                logger.warning(f"{HISTORICAL_STATS_FOR_RANKING_FILE} is missing expected columns for tie-breaking. Results may not use full historical context.")
        except Exception as e:
            logger.error(f"Error loading long-term historical symbol stats: {e}")
            long_term_historical_perf_df = None
    else:
        logger.warning(f"Long-term historical stats file not found: {HISTORICAL_STATS_FOR_RANKING_FILE}. Proceeding without historical tie-breaking.")
        long_term_historical_perf_df = None

# --- Helper Functions (load_symbols, fetch_stock_data_yf, calculate_indicators, detect_setup, calculate_potential_trade_params, apply_high_probability_filter_live) ---
# These should be identical to the robust versions in your create_historical_performance.py or the latest high_current.py
# For brevity, I will include the ones from the last version of high_current.py that included score distribution.
# Ensure these are robust and match the logic used in your backtests if you want consistency.

def load_symbols():
    all_symbols = set() 
    for market, filename in TICKER_FILES.items():
        loaded_from_file = False
        try:
            if os.path.exists(filename):
                df_tickers = pd.read_csv(filename, header=0)
                symbols_from_file_list = []
                df_cols_lower = [str(col).lower() for col in df_tickers.columns]
                if 'symbol' in df_cols_lower:
                    symbol_col_name = df_tickers.columns[df_cols_lower.index('symbol')]
                    symbols_from_file_list = df_tickers[symbol_col_name].tolist()
                elif not df_tickers.empty: symbols_from_file_list = df_tickers.iloc[:, 0].tolist()
                
                market_symbols_from_file = [str(s).strip() for s in symbols_from_file_list if isinstance(s, (str, float, int)) and str(s).strip()]
                if market_symbols_from_file:
                    logger.info(f"Loaded {len(market_symbols_from_file)} {market.upper()} symbols from {filename}")
                    all_symbols.update(market_symbols_from_file); loaded_from_file = True
                else: logger.warning(f"{market.upper()} tickers file '{filename}' was present but empty/malformed.")
            else: logger.info(f"{market.upper()} tickers file '{filename}' not found.")
            if not loaded_from_file: 
                logger.info(f"Attempting to use default list for {market.upper()} symbols.")
                market_symbols_from_default = DEFAULT_SYMBOLS.get(market, [])
                if market_symbols_from_default:
                    logger.info(f"Using {len(market_symbols_from_default)} default {market.upper()} symbols.")
                    all_symbols.update(market_symbols_from_default)
                else: logger.warning(f"No default symbols for {market.upper()}.")
        except Exception as e:
            logger.error(f"Error processing {market.upper()} symbols (file: {filename}): {e}. Using defaults if available.")
            market_symbols_from_default = DEFAULT_SYMBOLS.get(market, [])
            if market_symbols_from_default: all_symbols.update(market_symbols_from_default)
    if not all_symbols: logger.error("CRITICAL: No symbols loaded. Exiting."); return []
    logger.info(f"Total unique symbols to scan: {len(all_symbols)}")
    return list(all_symbols)

def fetch_stock_data_yf(symbol, period=DATA_FETCH_PERIOD):
    try:
        ticker = yf.Ticker(symbol)
        df = ticker.history(period=period, auto_adjust=True) 
        if df.empty: logger.warning(f"No data for {symbol} via yfinance for {period}."); return None
        df.rename(columns={'Open': 'Open', 'High': 'High', 'Low': 'Low', 'Close': 'Close', 'Volume': 'Volume'}, inplace=True, errors='ignore')
        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        if not all(col in df.columns for col in required_columns):
            logger.error(f"Missing required columns in {symbol} yf data (got {list(df.columns)})"); return None
        for col in required_columns: df[col] = pd.to_numeric(df[col], errors='coerce')
        df.dropna(subset=required_columns, inplace=True); df.sort_index(inplace=True)
        if len(df) < STRATEGY_PARAMS['min_data_days']:
            logger.warning(f"Not enough data for {symbol} ({len(df)} days). Need {STRATEGY_PARAMS['min_data_days']}."); return None
        return df
    except Exception as e: logger.error(f"Error fetching data for {symbol}: {e}"); return None

def calculate_indicators(df):
    # (This should be the same robust version as in create_historical_performance.py)
    df_indicators = df.copy()
    for period in [5, 10, 20, 50, 200]:
        if 'Close' in df_indicators.columns and len(df_indicators['Close']) >= period:
            df_indicators[f'ma{period}'] = df_indicators['Close'].rolling(window=period, min_periods=period).mean()
        else: df_indicators[f'ma{period}'] = np.nan
    if 'ma5' in df_indicators.columns and not df_indicators['ma5'].isnull().all():
        df_indicators['ma5_slope'] = df_indicators['ma5'].diff() / df_indicators['ma5'].shift(1)
        if 'ma5_slope' in df_indicators.columns and not df_indicators['ma5_slope'].isnull().all(): 
             df_indicators['ma5_slope_3day'] = df_indicators['ma5_slope'].rolling(window=3, min_periods=1).mean()
             df_indicators['ma5_slope_5day'] = df_indicators['ma5_slope'].rolling(window=5, min_periods=1).mean()
        else: df_indicators['ma5_slope_3day'], df_indicators['ma5_slope_5day'] = np.nan, np.nan
        df_indicators['ma5_slope_up'] = (df_indicators.get('ma5_slope', pd.Series(dtype=float)) > 0).astype(int)
        df_indicators['ma5_above_price'] = (df_indicators['ma5'] > df_indicators['Close']).astype(int)
    else:
        for col in ['ma5_slope','ma5_slope_3day','ma5_slope_5day','ma5_slope_up','ma5_above_price']: df_indicators[col]=np.nan
    if 'Close' in df_indicators.columns and not df_indicators['Close'].isnull().all():
        delta = df_indicators['Close'].diff()
        gain = delta.where(delta > 0, 0).rolling(window=14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        rs = gain / loss.replace(0, np.nan); df_indicators['rsi'] = 100 - (100 / (1 + rs)); df_indicators['rsi'].fillna(50, inplace=True) 
        df_indicators['rsi_change'] = df_indicators['rsi'].diff(); df_indicators['rsi_oversold'] = (df_indicators['rsi'] < 30).astype(int)
        if 'High' in df.columns and 'Low' in df.columns: 
            high_low = df_indicators['High'] - df_indicators['Low']; high_close = np.abs(df_indicators['High'] - df_indicators['Close'].shift())
            low_close = np.abs(df_indicators['Low'] - df_indicators['Close'].shift()); ranges = pd.concat([high_low, high_close, low_close], axis=1)
            true_range = ranges.max(axis=1, skipna=False); df_indicators['ATR'] = true_range.rolling(window=14, min_periods=14).mean()
        else: df_indicators['ATR'] = np.nan
    else: 
        for col in ['rsi','rsi_change','rsi_oversold','ATR']: df_indicators[col]=np.nan
    if 'Volume' in df_indicators.columns and 'Close' in df_indicators.columns and not df_indicators['Volume'].isnull().all() and df_indicators['Volume'].sum(skipna=True) > 0 :
        cumulative_volume = df_indicators['Volume'].cumsum()
        df_indicators['VWAP'] = np.where(cumulative_volume > 0, (df_indicators['Close'] * df_indicators['Volume']).cumsum() / cumulative_volume, np.nan)
        rolling_mean_volume = df_indicators['Volume'].rolling(window=20, min_periods=1).mean()
        df_indicators['volume_ratio'] = np.where(rolling_mean_volume > 0, df_indicators['Volume'] / rolling_mean_volume, np.nan)
        df_indicators['prev_day_volume_ratio'] = df_indicators['volume_ratio'].shift(1)
        df_indicators['volume_increasing'] = (df_indicators['Volume'] > df_indicators['Volume'].shift(1)).astype(int)
    else:
        for col in ['VWAP','volume_ratio','prev_day_volume_ratio','volume_increasing']: df_indicators[col]=np.nan
    if 'Close' in df_indicators.columns:
        for p in [1,2,3]: df_indicators[f'prev{p}_close_change'] = df_indicators['Close'].pct_change(p)
        df_indicators['close_vs_prev_close'] = df_indicators['Close'].pct_change()
    if 'Open' in df_indicators.columns and 'Close' in df_indicators.columns and not df_indicators['Open'].isnull().all() and not df_indicators['Open'].eq(0).all(): 
        df_indicators['close_vs_open'] = (df_indicators['Close'] - df_indicators['Open']) / df_indicators['Open'].replace(0, np.nan)
    else: df_indicators['close_vs_open'] = np.nan
    if 'High' in df_indicators.columns and 'Low' in df_indicators.columns and not df_indicators['Low'].isnull().all() and not df_indicators['Low'].eq(0).all(): 
        df_indicators['high_vs_low_range'] = (df_indicators['High'] - df_indicators['Low']) / df_indicators['Low'].replace(0, np.nan)
    else: df_indicators['high_vs_low_range'] = np.nan
    if all(x in df_indicators.columns and not df_indicators[x].isnull().all() for x in ['ma20', 'ma50', 'ma5', 'ma200']):
        df_indicators['day_thick_line_value'] = df_indicators['ma20'] - df_indicators['ma50']
        df_indicators['day_thick_line_slope'] = df_indicators['day_thick_line_value'].diff()
        df_indicators['day_thick_line_green'] = (df_indicators['day_thick_line_value'] > 0).astype(int)
        df_indicators['day_hist_value'] = df_indicators['ma5'] - df_indicators['ma20']
        df_indicators['day_hist_green'] = (df_indicators['day_hist_value'] > 0).astype(int)
        df_indicators['week_thick_line_value'] = df_indicators['ma50'] - df_indicators['ma200']
        df_indicators['week_red_below_zero_turns_green'] = ((df_indicators['week_thick_line_value'].shift(1) < 0) & (df_indicators['week_thick_line_value'] > 0)).astype(int)
    else:
        for col in ['day_thick_line_value','day_thick_line_slope','day_thick_line_green','day_hist_value','day_hist_green','week_thick_line_value','week_red_below_zero_turns_green']: df_indicators[col]=np.nan
    return df_indicators.dropna(subset=['ATR', 'ma200', 'rsi']) # Ensure key indicators are present

def detect_setup(df, idx=-1):
    # (Identical to the robust version from previous script)
    required_for_any_setup = ['rsi', 'close_vs_open', 'day_thick_line_green', 'ma5', 'ma20', 'ma50', 'ATR']
    if not all(col in df.columns for col in required_for_any_setup): return False, None, None
    effective_idx = len(df) - 1 if idx == -1 else idx
    if not (1 <= effective_idx < len(df)): return False, None, None 
    current_values = {col: df[col].iloc[effective_idx] for col in required_for_any_setup if col in df.columns}
    prev_values = {col: df[col].iloc[effective_idx-1] for col in required_for_any_setup if col in df.columns}
    if any(pd.isna(v) for v in current_values.values()) or any(pd.isna(v) for v in prev_values.values()): return False, None, None
    setup_detected, setup_type, tier = False, None, None
    current_rsi, prev_rsi = current_values['rsi'], prev_values['rsi']
    current_close_vs_open, current_day_thick_line_green = current_values['close_vs_open'], current_values['day_thick_line_green']
    current_ma5, prev_ma5 = current_values['ma5'], prev_values['ma5']
    current_ma20, prev_ma20 = current_values['ma20'], prev_values['ma20']
    current_ma50, prev_ma50 = current_values['ma50'], prev_values['ma50']
    current_volume_ratio = df['volume_ratio'].iloc[effective_idx] if 'volume_ratio' in df.columns and not pd.isna(df['volume_ratio'].iloc[effective_idx]) else np.nan
    if current_day_thick_line_green == 1 and current_rsi > 30 and prev_rsi <= 30:
        setup_detected, setup_type, tier = True, 'BOTTOM_TURN', 'high'
    elif (current_ma5 > current_ma20 and prev_ma5 <= prev_ma20) or \
         (current_ma5 > current_ma50 and prev_ma5 <= prev_ma50):
        setup_detected, setup_type, tier = True, 'MA_CROSS', 'medium'
    elif not pd.isna(current_volume_ratio) and not pd.isna(current_close_vs_open) and \
         ((current_volume_ratio > STRATEGY_PARAMS['volume_spike_threshold'] and current_close_vs_open > 0) or \
          (current_volume_ratio > 1.0 and current_close_vs_open > 0.01)):
        setup_detected, setup_type, tier = True, 'VOLUME_SPIKE', 'low'
    elif not pd.isna(current_close_vs_open) and current_rsi > 30 and prev_rsi <= 30 and current_close_vs_open > 0: 
        setup_detected, setup_type, tier = True, 'VOLUME_SPIKE', 'low' 
    return setup_detected, setup_type, tier

def calculate_potential_trade_params(df, entry_idx=-1):
    # (Identical to previous live scanner)
    effective_idx = len(df) - 1 if entry_idx == -1 else entry_idx
    if not ('ATR' in df.columns and 'Close' in df.columns and 
            not pd.isna(df['ATR'].iloc[effective_idx]) and 
            not pd.isna(df['Close'].iloc[effective_idx])): return None
    entry_price, atr_val = df['Close'].iloc[effective_idx], df['ATR'].iloc[effective_idx]
    if pd.isna(atr_val) or atr_val == 0: return None
    stop_loss_price = entry_price - (atr_val * STRATEGY_PARAMS['atr_multiplier'])
    target_price = entry_price + (atr_val * STRATEGY_PARAMS['atr_multiplier'] * STRATEGY_PARAMS['target_multiplier'])
    risk_reward_ratio = (target_price - entry_price) / (entry_price - stop_loss_price) if (entry_price - stop_loss_price) > 1e-9 else 0
    return {'entry_price': entry_price, 'stop_loss_price': stop_loss_price, 'target_price': target_price,
            'risk_reward_ratio': risk_reward_ratio, 'atr': atr_val}

def apply_high_probability_filter_live(potential_trade, setup_type, tier, params):
    # (Identical to previous live scanner but takes params)
    score = 0.0
    if potential_trade['risk_reward_ratio'] < params['risk_reward_ratio_threshold']: return False, 0.0
    score += min(potential_trade['risk_reward_ratio'] / 3.0, 1.0) * 40 
    if params['prioritize_volume_spike'] and setup_type == 'VOLUME_SPIKE': score += 35
    elif setup_type == 'BOTTOM_TURN': score += 25
    elif setup_type == 'MA_CROSS': score += 10
    if params['prioritize_low_tier'] and tier == 'low': score += 25
    elif tier == 'high': score += 15
    elif tier == 'medium': score += 10
    normalized_score = min(score / 100.0, 1.0)
    if normalized_score < params['win_rate_threshold']: # Use threshold from params
        if normalized_score > params['win_rate_threshold'] * 0.9 and np.random.random() < 0.05: return True, normalized_score
        return False, normalized_score
    return True, normalized_score

def find_current_setups(params): # Pass current STRATEGY_PARAMS
    logger.info("Scanning for current high probability setups...")
    symbols_to_scan = load_symbols()
    if not symbols_to_scan: return []
    
    potential_setups_today = []
    for symbol in tqdm(symbols_to_scan, desc="Scanning Symbols for Live Signals"):
        df_raw = fetch_stock_data_yf(symbol, period=DATA_FETCH_PERIOD) # Use DATA_FETCH_PERIOD
        if df_raw is None: continue
        df_indicators = calculate_indicators(df_raw)
        if df_indicators is None or df_indicators.empty or len(df_indicators) < params['min_data_days'] or pd.isna(df_indicators['Close'].iloc[-1]):
            logger.debug(f"Insufficient/invalid indicator data for {symbol}.") # Changed to debug
            continue
        setup_detected, setup_type, tier = detect_setup(df_indicators, idx=-1)
        if setup_detected:
            trade_params = calculate_potential_trade_params(df_indicators, entry_idx=-1)
            if trade_params is None: continue
            passes_filter, score = apply_high_probability_filter_live(trade_params, setup_type, tier, params) # Pass params
            if passes_filter:
                setup_info = {
                    'symbol': symbol, 'date': df_indicators.index[-1].date(), 'setup_type': setup_type, 'tier': tier,
                    'score': score, 'entry_price': trade_params['entry_price'], 
                    'stop_loss_price': trade_params['stop_loss_price'], 'target_price': trade_params['target_price'],
                    'risk_reward_ratio': trade_params['risk_reward_ratio'], 'atr': trade_params['atr'],
                    'latest_close': df_indicators['Close'].iloc[-1],
                    'hist_strength_score': -np.inf, 'hist_win_rate': 0.0, 'hist_total_trades': 0
                }
                if long_term_historical_perf_df is not None and not long_term_historical_perf_df.empty:
                    symbol_hist_data = long_term_historical_perf_df[long_term_historical_perf_df['symbol'] == symbol]
                    if not symbol_hist_data.empty:
                        setup_info['hist_strength_score'] = symbol_hist_data['hist_strength_score'].iloc[0]
                        setup_info['hist_win_rate'] = symbol_hist_data['hist_win_rate'].iloc[0]
                        setup_info['hist_total_trades'] = symbol_hist_data['hist_total_trades'].iloc[0]
                potential_setups_today.append(setup_info)
                logger.debug(f"  Potentially QUALIFIED: {symbol} | Score: {score:.3f} | Hist Str: {setup_info['hist_strength_score']:.2f}")
            else: logger.debug(f"  FILTERED OUT (Live): {symbol} | Score: {score:.3f} | Setup: {setup_type}")
    
    # Sort by primary score, then by historical_strength_score for tie-breaking
    potential_setups_today.sort(key=lambda x: (x['score'], x['hist_strength_score']), reverse=True)
    return potential_setups_today

def print_trade_summary_and_distribution(all_qualified_setups, score_bins):
    # (Identical to previous live scanner)
    total_setups = len(all_qualified_setups)
    logger.info(f"\\n--- Trade Candidate Summary (Today) ---")
    logger.info(f"Total qualified setups found today (before daily cap): {total_setups}")
    if total_setups == 0: logger.info("No setups met the criteria today."); logger.info("--- End of Summary ---"); return
    # Explicitly type bin_counts to satisfy the type checker
    bin_counts: OrderedDict[str, Any] = OrderedDict([(f"{l:.2f}-<{u:.2f}", 0) for l, u in score_bins])
    for setup_item in all_qualified_setups:
        score = setup_item['score']
        for lower, upper in score_bins:
            if lower <= score < upper: bin_counts[f"{lower:.2f}-<{upper:.2f}"] += 1; break
    logger.info("Distribution by Score Range (Today's Candidates):")
    has_trades_in_bins = False
    for bin_range, count in bin_counts.items():
        if count > 0: logger.info(f"  Score {bin_range}: {count} trade(s)"); has_trades_in_bins = True
    if not has_trades_in_bins: logger.info("  No trades fell into defined score bins.")
    logger.info("--- End of Summary ---")

def main():
    logger.info("Starting High Probability Live Signal Generator (Refined)...")
    
    load_long_term_historical_stats() # Load historical performance for tie-breaking
    
    # `create_dummy_ticker_files()` is not needed if ticker files are managed externally
    # If you want it for first-time setup, ensure paths in it are also correct.
    
    all_potential_signals_today = find_current_setups(STRATEGY_PARAMS) # Pass current params
    
    print_trade_summary_and_distribution(all_potential_signals_today, SCORE_BINS)

    if all_potential_signals_today:
        # --- MODIFIED: Select only the top 1 trade for the day ---
        final_trade_for_today = all_potential_signals_today[:1] 
        logger.info(f"\n--- Top Selected Trade Candidate for Today (Max 1) ---")

        for i, trade in enumerate(final_trade_for_today, start=1):
            print(f"\nTrade {i}:")
            print(f"  Symbol: {trade['symbol']}")
            print(f"  Date: {trade['date']}")
            print(f"  Setup Type: {trade['setup_type']} (Tier: {trade['tier']})")
            print(f"  Strategy Score: {trade['score']:.3f}")
            if pd.notna(trade['hist_strength_score']) and trade['hist_strength_score'] > -np.inf:
                print(f"  Historical Strength: {trade['hist_strength_score']:.2f} (Win Rate: {trade['hist_win_rate']:.2%}, Trades: {int(trade['hist_total_trades'])})")
            else:
                print(f"  Historical Strength: N/A")
            print(f"  Current Close: {trade['latest_close']:.2f}")
            print(f"  Potential Entry: ~{trade['entry_price']:.2f}")
            print(f"  Potential Stop-Loss: {trade['stop_loss_price']:.2f}")
        print(f"  Potential Target: {trade['target_price']:.2f}")
        print(f"  Potential R:R: {trade['risk_reward_ratio']:.2f}")
        print(f"  ATR: {trade['atr']:.3f}")

        logger.info("\nNote: Weekly trade limit (e.g., max 3) should be managed by the user based on daily signals.")
            
    else:
        logger.info("No trade candidates met the refined criteria for today.")
            
    logger.info("\nLive Signal Generator finished.")
    logger.info("Disclaimer: This is NOT financial advice. Data from yfinance can have delays. Always do your own research.")

if __name__ == "__main__":
    main()
